{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle VGG16 est un modèle de réseau neuronal convolutionnel proposé par K. Simonyan et A. Zisserman de l’Université d’Oxford dans l’article « Very Deep Convolutional Networks for Large-Scale Image Recognition ». \n",
    "Il s'agit d' un réseau neuronal convolutionnel  composé de 16 couches de profondeur.\n",
    "Le modèle atteint 92,7% top-5 précision de test dans ImageNet, qui est un jeu de données de plus de 14 millions d’images appartenant à 1000 classes. \n",
    "\n",
    "C’était l’un des fameux modèles soumis à ILSVRC-2014. Il améliore AlexNet en remplaçant les grands filtres de la taille d’un noyau (11 et 5 dans la première et la deuxième couche convolutionnelle, respectivement) par plusieurs filtres de la taille d’un noyau 3×3 l’un après l’autre. VGG16 a été formé pendant des semaines et utilisait NVIDIA Titan Black GPU.\n",
    "\n",
    "Le réseau préformé peut classer les images en 1000 catégories d’objets, telles que le clavier, la souris, le crayon et de nombreux animaux. En conséquence, le réseau a appris de riches représentations de fonctionnalités pour un large éventail d’images. Le réseau a une taille d’entrée d’image de 224 par 224. Pour plus de réseaux préentraînés dans MATLAB.\n",
    "\n",
    "VGG-16 est constitué de plusieurs couches, dont 13 couches de convolution et 3 fully-connected. Il doit donc apprendre les poids de 16 couches.\n",
    "\n",
    "Il prend en entrée une image en couleurs de taille 224  × 224 px et la classifie dans une des 1000 classes. Il renvoie donc un vecteur de taille 1000, qui contient les probabilités d'appartenance à chacune des classes. \n",
    "\n",
    "Chaque couche de convolution utilise des filtres en couleurs de taille 3  ×3 px, déplacés avec un pas de 1 pixel. Le zero-padding vaut 1 pixel afin que les volumes en entrée aient les mêmes dimensions en sortie. Le nombre de filtres varie selon le \"bloc\" dans lequel la couche se trouve. De plus, un paramètre de biais est introduit dans le produit de convolution pour chaque filtre.\n",
    "\n",
    "Chaque couche de convolution a pour fonction d'activation une ReLU. Autrement dit, il y a toujours une couche de correction ReLU après une couche de convolution.\n",
    "\n",
    "L'opération de pooling est réalisée avec des cellules de taille 2 × 2 px et un pas de 2 px – les cellules ne se chevauchent donc pas.\n",
    "\n",
    "Les deux premières couches fully-connected calculent chacune un vecteur de taille 4096, et sont chacune suivies d'une couche ReLU. La dernière renvoie le vecteur de probabilités de taille 1000 (le nombre de classes) en appliquant la fonction softmax. De plus, ces trois couches utilisent un paramètre de biais pour chaque élément du vecteur en sortie. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
